{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression using the gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I'll show you the basis of the neural networks. One of the most importants concepts in neural networks is the gradient descent, this is the base of training a neural network. In this notebook we will optimize a simple linear regression with the most simple gradient descent. In real problems optimizers are used in orther to converge faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example we'll use simple dataset of sklearn. This is dataset contains 10 variables and a target. In a real problem we would inspect and preprocess the data but, in this study we just care about the gradient descent algorism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  target  \n",
       "0 -0.002592  0.019908 -0.017646   151.0  \n",
       "1 -0.039493 -0.068330 -0.092204    75.0  \n",
       "2 -0.002592  0.002864 -0.025930   141.0  \n",
       "3  0.034309  0.022692 -0.009362   206.0  \n",
       "4 -0.002592 -0.031991 -0.046641   135.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "df = pd.DataFrame(data= np.c_[diabetes['data'], diabetes['target']],\n",
    "                     columns= diabetes['feature_names'] + ['target'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = df[df.columns[:-1]].to_numpy()\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = df.target.to_numpy().reshape((-1,1)) \n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first think we have to do is defining the model, the model will take inputs and then will compute the target using the input variables. In this case the model will be a linear function.\n",
    "\n",
    "* We define the model as: $ prediction = X*m +n $, where:\n",
    "* $n$ : The bias.\n",
    "* $m$ : The weights.\n",
    "* $x$ : The inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create two tensors, imagine tensors like tensorflow numpy arrays. This tensors will contain the weights. We initialize with 0.5. We don't care about the shape, they'll automatically be adapted. The we define the predict function, the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.Variable(0.5, shape=tf.TensorShape(None))\n",
    "b = tf.Variable(0.5, shape=tf.TensorShape(None))\n",
    "\n",
    "def predict(X):\n",
    "    return(tf.math.reduce_sum(X*m, 1) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined the inputs taking all columns and rows except the target. This will be the X of our model.\n",
    "As you can see we'll have 10 weights, so the model will predict with the following function:\n",
    "\n",
    "* $ prediction = x_1.w_1 + x_2.w_2 +... + x_{9}.w_{10} + b $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the loss function, this is the function that we want to minimize. In this case we want to minimize the error between the predicted value and the real value, to do this we'll use the mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(prediction, real):\n",
    "    return tf.math.reduce_mean(((prediction - real)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all ready, here comes the most intereseting part, the gradient descent. The idea behind this algorism is very simple. We'll just minimize the error of the model descending step by step, using the partial derivatives of the loss function respect each variable. Let's see how it works. First we present the pseudocode:\n",
    "* While current_step < total_steps: \n",
    "* 1. Compute the model prediction.\n",
    "* 2. Compute the loss using the prediction and the real values.\n",
    "* 3. Compute the gradient of the loss respect each variable.\n",
    "* 4. Update the weights using the gradient and the learning rate.\n",
    "* 5. Step ++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define two important parameters for the alogrism. The learning rate, this is what will guide the descent. If is bigger the descent will be faster but incosistent, if is smaller the descent will be more consistent but slower. Deciding this parameter is so important becuase a high or low learning rate can cause that the model never converge, it afects directly the algorism performance. \n",
    "In this case just for show we will compute just 10 steps. Then we define the steps, this will be the number of times that we update the weigths using all the dataset, we are using batches of all dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 20\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(28922.615, shape=(), dtype=float32)\n",
      "========\n",
      "tf.Tensor(20645.24, shape=(), dtype=float32)\n",
      "========\n",
      "tf.Tensor(15347.715, shape=(), dtype=float32)\n",
      "========\n",
      "tf.Tensor(11957.302, shape=(), dtype=float32)\n",
      "========\n",
      "tf.Tensor(9787.4375, shape=(), dtype=float32)\n",
      "========\n",
      "tf.Tensor(8398.724, shape=(), dtype=float32)\n",
      "========\n",
      "tf.Tensor(7509.9463, shape=(), dtype=float32)\n",
      "========\n",
      "tf.Tensor(6941.129, shape=(), dtype=float32)\n",
      "========\n",
      "tf.Tensor(6577.0854, shape=(), dtype=float32)\n",
      "========\n",
      "tf.Tensor(6344.0967, shape=(), dtype=float32)\n",
      "========\n",
      "tf.Tensor(6194.9854, shape=(), dtype=float32)\n",
      "========\n",
      "tf.Tensor(6099.553, shape=(), dtype=float32)\n",
      "========\n",
      "tf.Tensor(6038.477, shape=(), dtype=float32)\n",
      "========\n",
      "tf.Tensor(5999.3877, shape=(), dtype=float32)\n",
      "========\n",
      "tf.Tensor(5974.3706, shape=(), dtype=float32)\n",
      "========\n",
      "tf.Tensor(5958.3594, shape=(), dtype=float32)\n",
      "========\n",
      "tf.Tensor(5948.113, shape=(), dtype=float32)\n",
      "========\n",
      "tf.Tensor(5941.5537, shape=(), dtype=float32)\n",
      "========\n",
      "tf.Tensor(5937.3564, shape=(), dtype=float32)\n",
      "========\n",
      "tf.Tensor(5934.6704, shape=(), dtype=float32)\n",
      "========\n"
     ]
    }
   ],
   "source": [
    "# We will save the loss though the steps\n",
    "loss_history = []\n",
    "\n",
    "# For each step\n",
    "for i in range(steps):\n",
    "    # We open a tensorflow's tape\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Say to tensorflow which variables to trace\n",
    "        tape.watch([m,b])\n",
    "        # Get the prediction by the model\n",
    "        prediction = predict(inputs)\n",
    "        # Compute the loss   \n",
    "        loss = mse(prediction,targets)\n",
    "        \n",
    "    # Get the gradients respect the variables.\n",
    "    grads = tape.gradient(loss, [m,b])\n",
    "    \n",
    "    # Update the weights\n",
    "    m = m - grads[0]*lr\n",
    "    b = b - grads[1]*lr\n",
    "    \n",
    "    loss_history.append(loss)\n",
    "    print(loss)\n",
    "    print(\"========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following figure we can see how the error between inputs and outputs is descending. That's it we've coded an algorism to optimize linear functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig ,ax = plt.subplots()\n",
    "ax.plot(loss_history)\n",
    "ax.set_title(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the model trainned, let's see how it works. We'll predict the first entry of the dataset, as you can see the difference between the prediction and the real value is so small. Now we can evaluate the model and take interessting metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prediction:  [150.40437] \n",
      " Real : [151.]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\",\"Prediction: \", predict(inputs[0:1]).numpy(),\"\\n\",\n",
    "      \"Real :\", targets[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
